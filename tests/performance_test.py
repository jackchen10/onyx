#!/usr/bin/env python3
"""
Onyx æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡å’Œè´Ÿè½½èƒ½åŠ›
"""

import requests
import time
import psutil
import threading
import statistics
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict

class PerformanceTestRunner:
    def __init__(self):
        self.backend_url = "http://localhost:8080"
        self.frontend_url = "http://localhost:3000"
        self.results = {}
    
    def print_header(self, title: str):
        """æ‰“å°æ ‡é¢˜"""
        print(f"\n{'='*60}")
        print(f"âš¡ {title}")
        print('='*60)

    def print_result(self, test_name: str, success: bool, details: str = ""):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        status = "âœ… é€šè¿‡" if success else "âŒ æœªè¾¾æ ‡"
        print(f"{status} {test_name}")
        if details:
            print(f"   è¯¦æƒ…: {details}")
    
    def get_system_metrics(self) -> Dict:
        """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        return {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "memory_used_gb": psutil.virtual_memory().used / (1024**3),
            "disk_usage_percent": psutil.disk_usage('/').percent if sys.platform != 'win32' else psutil.disk_usage('C:').percent
        }
    
    def test_api_response_time(self) -> Dict:
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        self.print_header("APIå“åº”æ—¶é—´æµ‹è¯•")
        
        endpoints = [
            "/health",
            "/settings", 
            "/auth/type",
            "/me",
            "/persona",
            "/llm/provider"
        ]
        
        response_times = {}
        
        for endpoint in endpoints:
            times = []
            print(f"æµ‹è¯• {endpoint}...")
            
            # æ¯ä¸ªç«¯ç‚¹æµ‹è¯•10æ¬¡
            for i in range(10):
                try:
                    start_time = time.time()
                    response = requests.get(f"{self.backend_url}{endpoint}", timeout=5)
                    end_time = time.time()
                    
                    if response.status_code == 200:
                        response_time = (end_time - start_time) * 1000
                        times.append(response_time)
                    else:
                        print(f"   âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                except Exception as e:
                    print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            
            if times:
                avg_time = statistics.mean(times)
                min_time = min(times)
                max_time = max(times)
                median_time = statistics.median(times)
                
                response_times[endpoint] = {
                    "average": avg_time,
                    "min": min_time,
                    "max": max_time,
                    "median": median_time,
                    "samples": len(times)
                }
                
                print(f"   âœ… å¹³å‡: {avg_time:.2f}ms, æœ€å°: {min_time:.2f}ms, æœ€å¤§: {max_time:.2f}ms")
            else:
                response_times[endpoint] = None
                print(f"   âŒ æ— æœ‰æ•ˆå“åº”")
        
        self.results["api_response_times"] = response_times
        return response_times
    
    def test_concurrent_requests(self, num_threads: int = 10, requests_per_thread: int = 5) -> Dict:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        self.print_header(f"å¹¶å‘è¯·æ±‚æµ‹è¯• ({num_threads} çº¿ç¨‹, æ¯çº¿ç¨‹ {requests_per_thread} è¯·æ±‚)")
        
        def make_request(thread_id: int, request_id: int) -> Dict:
            """å‘é€å•ä¸ªè¯·æ±‚"""
            try:
                start_time = time.time()
                response = requests.get(f"{self.backend_url}/health", timeout=10)
                end_time = time.time()
                
                return {
                    "thread_id": thread_id,
                    "request_id": request_id,
                    "success": response.status_code == 200,
                    "response_time": (end_time - start_time) * 1000,
                    "status_code": response.status_code
                }
            except Exception as e:
                return {
                    "thread_id": thread_id,
                    "request_id": request_id,
                    "success": False,
                    "response_time": 0,
                    "error": str(e)
                }
        
        # è®°å½•å¼€å§‹æ—¶çš„ç³»ç»ŸæŒ‡æ ‡
        start_metrics = self.get_system_metrics()
        start_time = time.time()
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        results = []
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = []
            for thread_id in range(num_threads):
                for request_id in range(requests_per_thread):
                    future = executor.submit(make_request, thread_id, request_id)
                    futures.append(future)
            
            for future in as_completed(futures):
                results.append(future.result())
        
        end_time = time.time()
        end_metrics = self.get_system_metrics()
        
        # åˆ†æç»“æœ
        successful_requests = [r for r in results if r['success']]
        failed_requests = [r for r in results if not r['success']]
        
        total_requests = len(results)
        success_rate = len(successful_requests) / total_requests * 100
        total_time = end_time - start_time
        requests_per_second = total_requests / total_time
        
        if successful_requests:
            response_times = [r['response_time'] for r in successful_requests]
            avg_response_time = statistics.mean(response_times)
            max_response_time = max(response_times)
            min_response_time = min(response_times)
        else:
            avg_response_time = max_response_time = min_response_time = 0
        
        # æ‰“å°ç»“æœ
        print(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"âœ… æˆåŠŸè¯·æ±‚: {len(successful_requests)}")
        print(f"âŒ å¤±è´¥è¯·æ±‚: {len(failed_requests)}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"âš¡ è¯·æ±‚/ç§’: {requests_per_second:.2f}")
        print(f"ğŸ• æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        print(f"ğŸŒ æœ€æ…¢å“åº”: {max_response_time:.2f}ms")
        print(f"ğŸš€ æœ€å¿«å“åº”: {min_response_time:.2f}ms")
        
        # ç³»ç»Ÿèµ„æºä½¿ç”¨
        print(f"\nğŸ’» ç³»ç»Ÿèµ„æºä½¿ç”¨:")
        print(f"   CPU: {start_metrics['cpu_percent']:.1f}% â†’ {end_metrics['cpu_percent']:.1f}%")
        print(f"   å†…å­˜: {start_metrics['memory_percent']:.1f}% â†’ {end_metrics['memory_percent']:.1f}%")
        
        concurrent_results = {
            "total_requests": total_requests,
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "success_rate": success_rate,
            "requests_per_second": requests_per_second,
            "total_time": total_time,
            "avg_response_time": avg_response_time,
            "max_response_time": max_response_time,
            "min_response_time": min_response_time,
            "start_metrics": start_metrics,
            "end_metrics": end_metrics
        }
        
        self.results["concurrent_test"] = concurrent_results
        return success_rate > 90  # 90%ä»¥ä¸ŠæˆåŠŸç‡è®¤ä¸ºé€šè¿‡
    
    def test_memory_usage(self) -> Dict:
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        self.print_header("å†…å­˜ä½¿ç”¨æµ‹è¯•")
        
        # è·å–Pythonè¿›ç¨‹
        python_processes = []
        node_processes = []
        
        for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cmdline']):
            try:
                if 'python' in proc.info['name'].lower():
                    cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                    if 'test_server.py' in cmdline or 'onyx' in cmdline:
                        python_processes.append(proc)
                elif 'node' in proc.info['name'].lower():
                    cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                    if 'next' in cmdline or '3000' in cmdline:
                        node_processes.append(proc)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨
        total_backend_memory = sum(proc.memory_info().rss for proc in python_processes) / (1024**2)
        total_frontend_memory = sum(proc.memory_info().rss for proc in node_processes) / (1024**2)
        
        print(f"ğŸ åç«¯è¿›ç¨‹æ•°: {len(python_processes)}")
        print(f"   å†…å­˜ä½¿ç”¨: {total_backend_memory:.1f} MB")
        
        print(f"ğŸŒ å‰ç«¯è¿›ç¨‹æ•°: {len(node_processes)}")
        print(f"   å†…å­˜ä½¿ç”¨: {total_frontend_memory:.1f} MB")
        
        print(f"ğŸ’¾ æ€»å†…å­˜ä½¿ç”¨: {total_backend_memory + total_frontend_memory:.1f} MB")
        
        # å†…å­˜ä½¿ç”¨åˆç†æ€§æ£€æŸ¥
        memory_ok = total_backend_memory < 1000 and total_frontend_memory < 1000  # å°äº1GB
        self.print_result("å†…å­˜ä½¿ç”¨åˆç†æ€§", memory_ok, 
                         f"æ€»ä½¿ç”¨: {total_backend_memory + total_frontend_memory:.1f}MB")
        
        memory_results = {
            "backend_processes": len(python_processes),
            "frontend_processes": len(node_processes),
            "backend_memory_mb": total_backend_memory,
            "frontend_memory_mb": total_frontend_memory,
            "total_memory_mb": total_backend_memory + total_frontend_memory,
            "memory_reasonable": memory_ok
        }
        
        self.results["memory_usage"] = memory_results
        return memory_ok
    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        self.print_header("æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        
        # APIæ€§èƒ½æ€»ç»“
        if "api_response_times" in self.results:
            api_times = self.results["api_response_times"]
            valid_times = [data for data in api_times.values() if data is not None]
            
            if valid_times:
                all_avg_times = [data["average"] for data in valid_times]
                overall_avg = statistics.mean(all_avg_times)
                print(f"ğŸš€ APIæ•´ä½“å¹³å‡å“åº”æ—¶é—´: {overall_avg:.2f}ms")
                
                fastest_endpoint = min(valid_times, key=lambda x: x["average"])
                slowest_endpoint = max(valid_times, key=lambda x: x["average"])
                
                print(f"âš¡ æœ€å¿«ç«¯ç‚¹: {fastest_endpoint['average']:.2f}ms")
                print(f"ğŸŒ æœ€æ…¢ç«¯ç‚¹: {slowest_endpoint['average']:.2f}ms")
        
        # å¹¶å‘æ€§èƒ½æ€»ç»“
        if "concurrent_test" in self.results:
            concurrent = self.results["concurrent_test"]
            print(f"ğŸ”„ å¹¶å‘å¤„ç†èƒ½åŠ›: {concurrent['requests_per_second']:.2f} è¯·æ±‚/ç§’")
            print(f"ğŸ“ˆ å¹¶å‘æˆåŠŸç‡: {concurrent['success_rate']:.1f}%")
        
        # å†…å­˜ä½¿ç”¨æ€»ç»“
        if "memory_usage" in self.results:
            memory = self.results["memory_usage"]
            print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜ä½¿ç”¨: {memory['total_memory_mb']:.1f}MB")
            print(f"ğŸ¯ å†…å­˜ä½¿ç”¨è¯„çº§: {'ä¼˜ç§€' if memory['total_memory_mb'] < 500 else 'è‰¯å¥½' if memory['total_memory_mb'] < 1000 else 'éœ€è¦ä¼˜åŒ–'}")

def main():
    """ä¸»å‡½æ•°"""
    runner = PerformanceTestRunner()
    
    print("âš¡ Onyx æ€§èƒ½æµ‹è¯•å¥—ä»¶")
    print("ğŸ“… æµ‹è¯•æ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S"))
    
    # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    api_ok = runner.test_api_response_time()
    concurrent_ok = runner.test_concurrent_requests()
    memory_ok = runner.test_memory_usage()
    
    # ç”ŸæˆæŠ¥å‘Š
    runner.generate_performance_report()
    
    all_ok = api_ok and concurrent_ok and memory_ok
    
    if all_ok:
        print("\nğŸ‰ æ€§èƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ€§èƒ½æµ‹è¯•æœªè¾¾æ ‡ï¼Œå»ºè®®ä¼˜åŒ–ã€‚")
    
    return all_ok

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
