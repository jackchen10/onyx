# Vespaæœç´¢å¼•æ“é…ç½®å®è·µæŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›Onyxå·¥ç¨‹ä¸­Vespaæœç´¢å¼•æ“çš„è¯¦ç»†é…ç½®è¯´æ˜å’Œæœ€ä½³å®è·µï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£å’Œä¼˜åŒ–æ··åˆæ£€ç´¢ç³»ç»Ÿã€‚

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [Schemaé…ç½®è¯¦è§£](#schemaé…ç½®è¯¦è§£)
3. [æ··åˆæ£€ç´¢å‚æ•°è°ƒä¼˜](#æ··åˆæ£€ç´¢å‚æ•°è°ƒä¼˜)
4. [æ€§èƒ½ä¼˜åŒ–é…ç½®](#æ€§èƒ½ä¼˜åŒ–é…ç½®)
5. [ç›‘æ§ä¸è°ƒè¯•](#ç›‘æ§ä¸è°ƒè¯•)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## âš™ï¸ ç¯å¢ƒé…ç½®

### åŸºç¡€ç¯å¢ƒå˜é‡

```bash
# Vespaè¿æ¥é…ç½®
VESPA_HOST=localhost                    # Vespaä¸»æœºåœ°å€
VESPA_PORT=8081                        # Vespa HTTPç«¯å£
VESPA_TENANT_PORT=19071                # Vespaç®¡ç†ç«¯å£

# éƒ¨ç½²é…ç½®
VESPA_DEPLOYMENT_ZIP=/app/onyx/vespa-app.zip
VESPA_CONFIG_SERVER_HOST=localhost     # é…ç½®æœåŠ¡å™¨åœ°å€

# æ€§èƒ½é…ç½®
VESPA_SEARCHER_THREADS=2               # æœç´¢çº¿ç¨‹æ•°
NUM_RETRIES_ON_STARTUP=10              # å¯åŠ¨é‡è¯•æ¬¡æ•°

# è¯­è¨€é…ç½®
VESPA_LANGUAGE_OVERRIDE=en             # å¼ºåˆ¶è¯­è¨€è®¾ç½®
```

### Docker Composeé…ç½®

```yaml
services:
  index:
    image: vespaengine/vespa:8.526.15
    container_name: vespa
    ports:
      - "8081:8081"     # HTTPæŸ¥è¯¢ç«¯å£
      - "19071:19071"   # é…ç½®ç«¯å£
    volumes:
      - vespa_data:/opt/vespa/var
    environment:
      - VESPA_CONFIGSERVERS=vespa
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/ApplicationStatus"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
```

## ğŸ—„ï¸ Schemaé…ç½®è¯¦è§£

### 1. åŸºç¡€æ–‡æ¡£ç»“æ„

```vespa
schema onyx_chunk {
    document onyx_chunk {
        # æ ¸å¿ƒæ ‡è¯†å­—æ®µ
        field document_id type string {
            indexing: summary | attribute
            rank: filter
            attribute: fast-search
        }
        
        field chunk_id type int {
            indexing: summary | attribute
        }
        
        # æ–‡æœ¬å†…å®¹å­—æ®µ
        field title type string {
            indexing: summary | index | attribute
            index: enable-bm25
            match: text
        }
        
        field content type string {
            indexing: summary | index
            index: enable-bm25
            match: text
        }
        
        # å‘é‡åµŒå…¥å­—æ®µ
        field title_embedding type tensor<float>(x[384]) {
            indexing: attribute | index
            attribute {
                distance-metric: angular
            }
        }
        
        field embeddings type tensor<float>(t{},x[384]) {
            indexing: attribute | index
            attribute {
                distance-metric: angular
            }
        }
    }
}
```

### 2. é«˜çº§å­—æ®µé…ç½®

```vespa
# å…ƒæ•°æ®å­—æ®µ
field source_type type string {
    indexing: summary | attribute
    rank: filter
    attribute: fast-search
}

field doc_updated_at type long {
    indexing: summary | attribute
    rank: filter
}

# æƒé™æ§åˆ¶
field access_control_list type weightedset<string> {
    indexing: summary | attribute
    rank: filter
}

# æ–‡æ¡£é›†åˆ
field document_sets type weightedset<string> {
    indexing: summary | attribute
    rank: filter
}

# æå‡å› å­
field boost type int {
    indexing: summary | attribute
    rank: filter
}
```

### 3. çŸ¥è¯†å›¾è°±æ”¯æŒ

```vespa
struct kg_relationship {
    field source type string {}
    field rel_type type string {}
    field target type string {}
}

field kg_relationships type array<kg_relationship> {
    indexing: summary | attribute
    struct-field source {
        indexing: attribute
        attribute: fast-search
    }
    struct-field rel_type {
        indexing: attribute
        attribute: fast-search
    }
    struct-field target {
        indexing: attribute
        attribute: fast-search
    }
}
```

## ğŸ” æ··åˆæ£€ç´¢å‚æ•°è°ƒä¼˜

### 1. Alphaå‚æ•°é…ç½®

```python
# é»˜è®¤æ··åˆæƒé‡é…ç½®
HYBRID_ALPHA = 0.5          # è¯­ä¹‰æ£€ç´¢æƒé‡50%
HYBRID_ALPHA_KEYWORD = 0.4  # å…³é”®è¯æ£€ç´¢ä¸­å‘é‡æƒé‡40%

# åŠ¨æ€è°ƒæ•´ç­–ç•¥
def get_optimal_alpha(query_type: str, query_length: int) -> float:
    """æ ¹æ®æŸ¥è¯¢ç±»å‹å’Œé•¿åº¦åŠ¨æ€è°ƒæ•´alphaå€¼"""
    if query_type == "factual":
        return 0.3  # äº‹å®æ€§æŸ¥è¯¢åå‘å…³é”®è¯
    elif query_type == "conceptual":
        return 0.7  # æ¦‚å¿µæ€§æŸ¥è¯¢åå‘è¯­ä¹‰
    elif query_length < 3:
        return 0.2  # çŸ­æŸ¥è¯¢åå‘å…³é”®è¯
    else:
        return 0.5  # é»˜è®¤å¹³è¡¡
```

### 2. æ ‡é¢˜å†…å®¹æ¯”ä¾‹è°ƒä¼˜

```python
# æ ‡é¢˜å†…å®¹æƒé‡é…ç½®
TITLE_CONTENT_RATIO = 0.3  # æ ‡é¢˜æƒé‡30%ï¼Œå†…å®¹æƒé‡70%

# æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´
def get_title_content_ratio(source_type: str) -> float:
    """æ ¹æ®æ•°æ®æºç±»å‹è°ƒæ•´æ ‡é¢˜å†…å®¹æ¯”ä¾‹"""
    ratios = {
        "confluence": 0.4,  # Wikiç±»æ–‡æ¡£æ ‡é¢˜æ›´é‡è¦
        "slack": 0.2,       # èŠå¤©æ¶ˆæ¯æ ‡é¢˜ä¸é‡è¦
        "email": 0.3,       # é‚®ä»¶æ ‡é¢˜ä¸­ç­‰é‡è¦
        "pdf": 0.5,         # PDFæ–‡æ¡£æ ‡é¢˜å¾ˆé‡è¦
    }
    return ratios.get(source_type, 0.3)
```

### 3. æ—¶é—´è¡°å‡é…ç½®

```python
# æ—¶é—´è¡°å‡å‚æ•°
DOC_TIME_DECAY = 0.5  # åŸºç¡€è¡°å‡å› å­
BASE_RECENCY_DECAY = 1.0
FAVOR_RECENT_DECAY_MULTIPLIER = 3.0

# è¡°å‡å…¬å¼: 1 / (1 + decay_factor * years_old)
def calculate_recency_bias(doc_age_years: float, decay_factor: float) -> float:
    """è®¡ç®—åŸºäºæ–‡æ¡£å¹´é¾„çš„æ–°è¿‘åº¦åç½®"""
    return 1.0 / (1.0 + decay_factor * doc_age_years)
```

## ğŸ¯ Ranking Profileä¼˜åŒ–

### 1. è¯­ä¹‰ä¼˜å…ˆProfile

```vespa
rank-profile hybrid_search_semantic_base_384 inherits default, default_rank {
    inputs {
        query(query_embedding) tensor<float>(x[384])
        query(alpha) double: 0.5
        query(title_content_ratio) double: 0.3
        query(decay_factor) double: 0.5
    }

    function title_vector_score() {
        expression {
            max(closeness(field, embeddings), closeness(field, title_embedding))
        }
    }

    # ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿå‘é‡ç­›é€‰
    first-phase {
        expression: query(title_content_ratio) * closeness(field, title_embedding) + (1 - query(title_content_ratio)) * closeness(field, embeddings)
    }

    # å…¨å±€é˜¶æ®µï¼šç²¾ç¡®æ··åˆè¯„åˆ†
    global-phase {
        expression {
            (
                # å‘é‡ç›¸ä¼¼åº¦åˆ†æ•°
                query(alpha) * (
                    (query(title_content_ratio) * normalize_linear(title_vector_score))
                    +
                    ((1 - query(title_content_ratio)) * normalize_linear(closeness(field, embeddings)))
                )
            )
            +
            # å…³é”®è¯ç›¸ä¼¼åº¦åˆ†æ•°
            (
                (1 - query(alpha)) * (
                    (query(title_content_ratio) * normalize_linear(bm25(title)))
                    +
                    ((1 - query(title_content_ratio)) * normalize_linear(bm25(content)))
                )
            )
        }
        # åº”ç”¨å„ç§æå‡å› å­
        * document_boost
        * recency_bias
        * aggregated_chunk_boost
        
        rerank-count: 1000
    }

    # è¾“å‡ºåŒ¹é…ç‰¹å¾ç”¨äºè°ƒè¯•
    match-features {
        bm25(title)
        bm25(content)
        closeness(field, title_embedding)
        closeness(field, embeddings)
        document_boost
        recency_bias
        aggregated_chunk_boost
        closest(embeddings)
    }
}
```

### 2. å…³é”®è¯ä¼˜å…ˆProfile

```vespa
rank-profile hybrid_search_keyword_base_384 inherits default, default_rank {
    # ç¬¬ä¸€é˜¶æ®µï¼šBM25å…³é”®è¯ç­›é€‰
    first-phase {
        expression: query(title_content_ratio) * bm25(title) + (1 - query(title_content_ratio)) * bm25(content)
    }
    
    # å…¨å±€é˜¶æ®µï¼šä¸è¯­ä¹‰Profileç›¸åŒçš„æ··åˆè¯„åˆ†
    global-phase {
        expression {
            # ç›¸åŒçš„æ··åˆè¯„åˆ†å…¬å¼
        }
        rerank-count: 1000
    }
}
```

### 3. ç®¡ç†å‘˜æœç´¢Profile

```vespa
rank-profile admin_search inherits default, default_rank {
    first-phase {
        expression: bm25(content) + (5 * bm25(title))
    }
    
    # ä¸ä½¿ç”¨å‘é‡æ£€ç´¢ï¼Œçº¯å…³é”®è¯åŒ¹é…
    # é€‚ç”¨äºç®¡ç†ç•Œé¢çš„ç²¾ç¡®æœç´¢
}
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–é…ç½®

### 1. æœåŠ¡é…ç½®ä¼˜åŒ–

```xml
<services version="1.0">
    <container id="default" version="1.0">
        <document-api/>
        <search/>
        <http>
            <server id="default" port="8081"/>
        </http>
        <nodes>
            <node hostalias="vespa-node"/>
        </nodes>
        <!-- è°ƒä¼˜é…ç½® -->
        <config name="container.qr">
            <filedistributor>
                <maxpendingbytes>134217728</maxpendingbytes>
            </filedistributor>
        </config>
    </container>
    
    <content id="onyx_index" version="1.0">
        <redundancy>1</redundancy>
        <documents>
            <document type="onyx_chunk" mode="index"/>
        </documents>
        <nodes>
            <node hostalias="vespa-node" distribution-key="0"/>
        </nodes>
        
        <!-- æ€§èƒ½è°ƒä¼˜ -->
        <tuning>
            <resource-limits>
                <disk>0.85</disk>
                <memory>0.8</memory>
            </resource-limits>
        </tuning>
        
        <engine>
            <proton>
                <tuning>
                    <searchnode>
                        <requestthreads>
                            <persearch>4</persearch>
                        </requestthreads>
                        <flushstrategy>
                            <native>
                                <total>
                                    <maxmemorygain>134217728</maxmemorygain>
                                </total>
                            </native>
                        </flushstrategy>
                    </searchnode>
                </tuning>
            </proton>
        </engine>
        
        <!-- æ‘˜è¦é…ç½® -->
        <config name="vespa.config.search.summary.juniperrc">
            <max_matches>3</max_matches>
            <length>750</length>
            <surround_max>350</surround_max>
            <min_length>300</min_length>
        </config>
    </content>
</services>
```

### 2. æŸ¥è¯¢ä¼˜åŒ–å‚æ•°

```python
# æŸ¥è¯¢å‚æ•°ä¼˜åŒ–
VESPA_TIMEOUT = 30  # æŸ¥è¯¢è¶…æ—¶æ—¶é—´
MAX_ID_SEARCH_QUERY_SIZE = 1000  # æ‰¹é‡æŸ¥è¯¢æœ€å¤§å¤§å°

# ç›®æ ‡å‘½ä¸­æ•°åŠ¨æ€è°ƒæ•´
def calculate_target_hits(num_to_retrieve: int) -> int:
    """åŠ¨æ€è®¡ç®—ç›®æ ‡å‘½ä¸­æ•°"""
    return max(10 * num_to_retrieve, 1000)

# æŸ¥è¯¢å‚æ•°æ„å»º
def build_query_params(
    query: str,
    query_embedding: list[float],
    hybrid_alpha: float,
    num_hits: int,
    ranking_profile: str
) -> dict:
    """æ„å»ºä¼˜åŒ–çš„æŸ¥è¯¢å‚æ•°"""
    return {
        "yql": build_yql_query(query),
        "query": query,
        "input.query(query_embedding)": str(query_embedding),
        "input.query(alpha)": hybrid_alpha,
        "hits": num_hits,
        "ranking.profile": ranking_profile,
        "timeout": VESPA_TIMEOUT,
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        "presentation.timing": True,
        "model.defaultIndex": "content",
        "model.type": "weakAnd",
    }
```

### 3. ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

```python
# æ‰¹é‡ç´¢å¼•é…ç½®
NUM_THREADS = 8  # ç´¢å¼•çº¿ç¨‹æ•°
BATCH_SIZE = 100  # æ‰¹é‡å¤§å°

def optimize_indexing_performance():
    """ç´¢å¼•æ€§èƒ½ä¼˜åŒ–é…ç½®"""
    return {
        "max_workers": NUM_THREADS,
        "batch_size": BATCH_SIZE,
        "timeout": 300,  # 5åˆ†é’Ÿè¶…æ—¶
        "retry_attempts": 3,
        "backoff_factor": 2,
    }

# æ–‡æ¡£é¢„å¤„ç†ä¼˜åŒ–
def preprocess_document(content: str) -> str:
    """æ–‡æ¡£é¢„å¤„ç†ä¼˜åŒ–"""
    # ç§»é™¤æ— æ•ˆUnicodeå­—ç¬¦
    content = remove_invalid_unicode_chars(content)
    # é™åˆ¶æ–‡æ¡£é•¿åº¦
    if len(content) > 50000:
        content = content[:50000] + "..."
    return content
```

## ğŸ“Š ç›‘æ§ä¸è°ƒè¯•

### 1. æŸ¥è¯¢æ€§èƒ½ç›‘æ§

```python
# å¯ç”¨è¯¦ç»†æ—¶é—´ä¿¡æ¯
LOG_VESPA_TIMING_INFORMATION = True

# æŸ¥è¯¢ç›‘æ§è£…é¥°å™¨
def monitor_query_performance(func):
    """æŸ¥è¯¢æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"Query completed in {duration:.3f}s")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed after {duration:.3f}s: {e}")
            raise
    return wrapper

# æ€§èƒ½æŒ‡æ ‡æ”¶é›†
class VespaMetrics:
    def __init__(self):
        self.query_count = 0
        self.total_time = 0.0
        self.error_count = 0
    
    def record_query(self, duration: float, success: bool):
        self.query_count += 1
        self.total_time += duration
        if not success:
            self.error_count += 1
    
    def get_stats(self) -> dict:
        return {
            "avg_latency": self.total_time / max(self.query_count, 1),
            "error_rate": self.error_count / max(self.query_count, 1),
            "total_queries": self.query_count,
        }
```

### 2. åŒ¹é…ç‰¹å¾åˆ†æ

```python
def analyze_match_features(vespa_response: dict) -> dict:
    """åˆ†æVespaè¿”å›çš„åŒ¹é…ç‰¹å¾"""
    features = {}
    for hit in vespa_response.get("root", {}).get("children", []):
        match_features = hit.get("fields", {}).get("matchfeatures", {})
        features[hit["id"]] = {
            "bm25_title": match_features.get("bm25(title)", 0),
            "bm25_content": match_features.get("bm25(content)", 0),
            "vector_title": match_features.get("closeness(field,title_embedding)", 0),
            "vector_content": match_features.get("closeness(field,embeddings)", 0),
            "document_boost": match_features.get("document_boost", 1),
            "recency_bias": match_features.get("recency_bias", 1),
        }
    return features

# è¯„åˆ†åˆ†æ
def analyze_scoring_distribution(features: dict) -> dict:
    """åˆ†æè¯„åˆ†åˆ†å¸ƒ"""
    bm25_scores = [f["bm25_content"] for f in features.values()]
    vector_scores = [f["vector_content"] for f in features.values()]
    
    return {
        "bm25_avg": sum(bm25_scores) / len(bm25_scores),
        "bm25_max": max(bm25_scores),
        "vector_avg": sum(vector_scores) / len(vector_scores),
        "vector_max": max(vector_scores),
    }
```

## ğŸ”§ æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜è¯Šæ–­

```python
# è¿æ¥é—®é¢˜è¯Šæ–­
def diagnose_vespa_connection():
    """è¯Šæ–­Vespaè¿æ¥é—®é¢˜"""
    try:
        response = requests.get(f"http://{VESPA_HOST}:{VESPA_PORT}/ApplicationStatus")
        if response.status_code == 200:
            logger.info("Vespa connection OK")
            return True
        else:
            logger.error(f"Vespa returned status {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"Failed to connect to Vespa: {e}")
        return False

# ç´¢å¼•é—®é¢˜è¯Šæ–­
def diagnose_indexing_issues(document_id: str):
    """è¯Šæ–­ç´¢å¼•é—®é¢˜"""
    try:
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        response = requests.get(
            f"http://{VESPA_HOST}:{VESPA_PORT}/document/v1/default/onyx_chunk/docid/{document_id}"
        )
        if response.status_code == 200:
            logger.info(f"Document {document_id} indexed successfully")
        else:
            logger.error(f"Document {document_id} not found in index")
    except Exception as e:
        logger.error(f"Error checking document {document_id}: {e}")

# æŸ¥è¯¢é—®é¢˜è¯Šæ–­
def diagnose_query_issues(query: str, expected_results: int):
    """è¯Šæ–­æŸ¥è¯¢é—®é¢˜"""
    # ç®€å•æŸ¥è¯¢æµ‹è¯•
    simple_params = {
        "yql": f"select * from onyx_chunk where userInput('{query}')",
        "hits": expected_results,
    }
    
    try:
        response = requests.post(
            f"http://{VESPA_HOST}:{VESPA_PORT}/search/",
            json=simple_params
        )
        result = response.json()
        actual_hits = len(result.get("root", {}).get("children", []))
        
        logger.info(f"Query '{query}' returned {actual_hits} hits (expected {expected_results})")
        
        if actual_hits == 0:
            logger.warning("No results found - check indexing and query syntax")
        
        return actual_hits
    except Exception as e:
        logger.error(f"Query diagnosis failed: {e}")
        return 0
```

### 2. æ€§èƒ½é—®é¢˜è§£å†³

```python
# æ…¢æŸ¥è¯¢åˆ†æ
def analyze_slow_queries(threshold_ms: int = 1000):
    """åˆ†ææ…¢æŸ¥è¯¢"""
    slow_queries = []
    
    # ä»æ—¥å¿—ä¸­æå–æ…¢æŸ¥è¯¢
    # å®é™…å®ç°éœ€è¦æ ¹æ®æ—¥å¿—æ ¼å¼è°ƒæ•´
    
    for query in slow_queries:
        logger.warning(f"Slow query detected: {query}")
        # åˆ†ææŸ¥è¯¢å¤æ‚åº¦
        # å»ºè®®ä¼˜åŒ–æ–¹æ¡ˆ
    
    return slow_queries

# å†…å­˜ä½¿ç”¨ä¼˜åŒ–
def optimize_memory_usage():
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    recommendations = []
    
    # æ£€æŸ¥ç´¢å¼•å¤§å°
    # æ£€æŸ¥æŸ¥è¯¢ç¼“å­˜
    # æ£€æŸ¥æ–‡æ¡£å¤§å°
    
    return recommendations
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-02-19  
**é€‚ç”¨ç‰ˆæœ¬**: Onyx v1.0+
