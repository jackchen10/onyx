# Linux服务器部署资源配置详细对比表

## 📊 完整镜像和容器清单

### Docker镜像列表 (按大小排序)
| 镜像名称 | 版本 | 大小 | 用途 | 必需性 |
|----------|------|------|------|--------|
| **基础镜像** | | | | |
| redis:7-alpine | 7.2 | ~30MB | 缓存服务 | 必需 |
| nginx:alpine | 1.24 | ~40MB | 反向代理 | 必需 |
| python:3.11-slim | 3.11 | ~120MB | Python运行时 | 必需 |
| node:18-alpine | 18.19 | ~170MB | Node.js构建 | 构建时需要 |
| postgres:14-alpine | 14.10 | ~200MB | 数据库 | 必需 |
| **自定义镜像** | | | | |
| onyx/web-frontend | latest | ~100MB | 前端应用 | 必需 |
| onyx/api-backend | latest | ~800MB | 后端API | 必需 |
| onyx/celery-worker | latest | ~800MB | 任务队列 | 必需 |
| onyx/model-server | latest | ~1.2GB | AI模型服务 | 必需 |
| **监控镜像** | | | | |
| prom/node-exporter | latest | ~20MB | 系统监控 | 可选 |
| prom/prometheus | latest | ~200MB | 指标收集 | 可选 |
| grafana/grafana | latest | ~300MB | 可视化 | 可选 |
| **总计** | | **~3.8GB** | | |

### 运行时容器资源分配

#### 最小化部署 (8GB RAM, 4核心)
| 容器名称 | CPU分配 | 内存分配 | 存储需求 | 端口 | 状态 |
|----------|---------|----------|----------|------|------|
| onyx-postgres | 1核心 | 2GB | 10GB | 5432 | 必需 |
| onyx-redis | 0.5核心 | 1GB | 2GB | 6379 | 必需 |
| onyx-api-backend | 1核心 | 2GB | 5GB | 8080 | 必需 |
| onyx-model-server | 1核心 | 2GB | 15GB | 9000 | 必需 |
| onyx-web-frontend | 0.25核心 | 512MB | 1GB | 3000 | 必需 |
| onyx-nginx-proxy | 0.25核心 | 256MB | 500MB | 80,443 | 必需 |
| **系统预留** | **0.5核心** | **256MB** | **5GB** | - | - |
| **总计** | **4核心** | **8GB** | **38.5GB** | - | - |

#### 标准单服务器部署 (32GB RAM, 8核心)
| 容器名称 | CPU分配 | 内存分配 | 存储需求 | 端口 | 状态 |
|----------|---------|----------|----------|------|------|
| onyx-postgres | 2核心 | 4GB | 30GB | 5432 | 必需 |
| onyx-redis | 1核心 | 2GB | 5GB | 6379 | 必需 |
| onyx-api-backend | 2核心 | 6GB | 10GB | 8080 | 必需 |
| onyx-model-server | 2核心 | 12GB | 50GB | 9000 | 必需 |
| onyx-celery-worker | 0.5核心 | 2GB | 5GB | - | 必需 |
| onyx-web-frontend | 0.25核心 | 1GB | 2GB | 3000 | 必需 |
| onyx-nginx-proxy | 0.25核心 | 512MB | 1GB | 80,443 | 必需 |
| **系统预留** | **1核心** | **4.5GB** | **20GB** | - | - |
| **总计** | **8核心** | **32GB** | **123GB** | - | - |

#### 集群部署 - 应用服务器 (32GB RAM, 8核心)
| 容器名称 | CPU分配 | 内存分配 | 存储需求 | 端口 | 实例数 |
|----------|---------|----------|----------|------|--------|
| onyx-api-backend | 3核心 | 6GB | 10GB | 8080 | 2个实例 |
| onyx-web-frontend | 0.5核心 | 1GB | 2GB | 3000 | 2个实例 |
| onyx-celery-worker | 0.5核心 | 2GB | 5GB | - | 2个实例 |
| onyx-nginx-proxy | 0.5核心 | 1GB | 2GB | 80,443 | 1个实例 |
| **系统预留** | **1核心** | **4GB** | **10GB** | - | - |
| **总计** | **8核心** | **32GB** | **46GB** | - | **7个容器** |

#### 集群部署 - AI服务器 (64GB RAM, 16核心)
| 容器名称 | CPU分配 | 内存分配 | 存储需求 | GPU | 实例数 |
|----------|---------|----------|----------|-----|--------|
| onyx-model-server-1 | 6核心 | 20GB | 100GB | GPU:0 | 1个实例 |
| onyx-model-server-2 | 6核心 | 20GB | 100GB | GPU:1 | 1个实例 |
| onyx-model-server-3 | 2核心 | 8GB | 50GB | CPU | 1个实例 |
| **系统预留** | **2核心** | **16GB** | **50GB** | - | - |
| **总计** | **16核心** | **64GB** | **300GB** | **2GPU** | **3个容器** |

#### 集群部署 - 数据库服务器 (64GB RAM, 12核心)
| 容器名称 | CPU分配 | 内存分配 | 存储需求 | 端口 | 角色 |
|----------|---------|----------|----------|------|------|
| onyx-postgres-master | 6核心 | 32GB | 500GB | 5432 | 主库 |
| onyx-postgres-slave | 2核心 | 16GB | 500GB | 5433 | 从库 |
| onyx-redis-master | 2核心 | 8GB | 50GB | 6379 | 主缓存 |
| onyx-redis-slave | 1核心 | 4GB | 50GB | 6380 | 从缓存 |
| **系统预留** | **1核心** | **4GB** | **100GB** | - | - |
| **总计** | **12核心** | **64GB** | **1.2TB** | - | **4个容器** |

## 🏗️ 服务器架构方案对比

### 方案1: 单服务器部署
```yaml
适用场景: 小型团队 (10-50人), 测试环境, 概念验证
服务器数量: 1台
总成本: $2,000-3,000/年

服务器配置:
  CPU: 8核心 Intel Xeon E-2288G
  内存: 32GB DDR4 ECC
  存储: 500GB NVMe SSD + 2TB SATA
  网络: 1Gbps
  操作系统: Ubuntu 22.04 LTS

容器分布:
  - 所有7个核心容器
  - 本地数据持久化
  - 单点故障风险

优势:
  ✅ 部署简单
  ✅ 成本最低
  ✅ 维护简单
  ✅ 适合快速原型

劣势:
  ❌ 单点故障
  ❌ 扩展性有限
  ❌ 性能瓶颈
  ❌ 无高可用
```

### 方案2: 双服务器部署
```yaml
适用场景: 中型企业 (50-200人), 生产环境, 高可用需求
服务器数量: 2台
总成本: $4,000-6,000/年

应用服务器:
  CPU: 8核心 Intel Xeon Gold 6248R
  内存: 32GB DDR4 ECC
  存储: 300GB NVMe SSD
  容器: API, Web, Worker, Proxy

数据AI服务器:
  CPU: 16核心 Intel Xeon Gold 6326
  内存: 64GB DDR4 ECC
  存储: 1TB NVMe SSD + 4TB SATA
  GPU: NVIDIA RTX A4000
  容器: Database, Cache, Model Server

优势:
  ✅ 服务分离
  ✅ 部分高可用
  ✅ 性能更好
  ✅ 可独立扩展

劣势:
  ❌ 成本增加
  ❌ 复杂度提升
  ❌ 仍有单点风险
```

### 方案3: 多服务器集群
```yaml
适用场景: 大型企业 (200+人), 关键业务, 高并发需求
服务器数量: 6台
总成本: $15,000-25,000/年

架构组成:
  - 1台负载均衡器 (4核心, 16GB)
  - 2台应用服务器 (12核心, 48GB)
  - 2台AI服务器 (20核心, 128GB, 2xGPU)
  - 1台数据库服务器 (16核心, 128GB)

优势:
  ✅ 完全高可用
  ✅ 水平扩展
  ✅ 性能最优
  ✅ 故障隔离
  ✅ 负载分散

劣势:
  ❌ 成本最高
  ❌ 复杂度最高
  ❌ 运维要求高
```

## 💾 存储需求详细分析

### 数据存储分类
```yaml
应用数据:
  - 用户上传文档: 10-100GB (取决于用户数量)
  - 数据库数据: 5-50GB (用户、会话、配置)
  - 搜索索引: 2-20GB (文档向量索引)

AI模型数据:
  - 预训练模型: 5-50GB (取决于模型大小)
  - 模型缓存: 2-20GB (推理结果缓存)
  - 临时文件: 1-10GB (处理过程文件)

系统数据:
  - Docker镜像: 4-8GB (所有镜像)
  - 系统日志: 1-10GB (应用和系统日志)
  - 备份数据: 20-200GB (数据备份)

总存储需求:
  最小: 50GB
  推荐: 200GB
  大规模: 500GB+
```

### 存储性能要求
```yaml
数据库存储:
  类型: NVMe SSD (推荐)
  IOPS: 10,000+ (4K随机读写)
  延迟: <1ms
  带宽: 500MB/s+

AI模型存储:
  类型: NVMe SSD (必需)
  IOPS: 5,000+ (顺序读取为主)
  延迟: <2ms
  带宽: 1GB/s+ (模型加载)

日志存储:
  类型: SATA SSD (可接受)
  IOPS: 1,000+
  延迟: <5ms
  带宽: 100MB/s+
```

## 🌐 网络配置需求

### 带宽需求
```yaml
最小化部署:
  上行带宽: 10Mbps
  下行带宽: 100Mbps
  并发连接: 100个
  适用: 10-20用户

标准部署:
  上行带宽: 100Mbps
  下行带宽: 1Gbps
  并发连接: 1,000个
  适用: 50-200用户

集群部署:
  上行带宽: 1Gbps
  下行带宽: 10Gbps
  并发连接: 10,000个
  适用: 200+用户
```

### 端口配置
```yaml
公网端口 (需要开放):
  - 80/tcp: HTTP访问
  - 443/tcp: HTTPS访问
  - 22/tcp: SSH管理

内网端口 (仅内部访问):
  - 5432/tcp: PostgreSQL
  - 6379/tcp: Redis
  - 8080/tcp: FastAPI后端
  - 9000/tcp: AI模型服务
  - 3000/tcp: Next.js前端

监控端口 (可选):
  - 9090/tcp: Prometheus
  - 3001/tcp: Grafana
  - 9100/tcp: Node Exporter
```

## 🔧 云服务器推荐配置

### AWS EC2实例推荐
```yaml
最小化部署:
  实例类型: t3.large
  vCPU: 2核心
  内存: 8GB
  存储: 100GB gp3
  网络: 最高5Gbps
  月费用: ~$70

标准部署:
  实例类型: m6i.2xlarge
  vCPU: 8核心
  内存: 32GB
  存储: 500GB gp3
  网络: 最高25Gbps
  月费用: ~$350

集群部署 - 应用服务器:
  实例类型: c6i.2xlarge
  vCPU: 8核心
  内存: 16GB
  存储: 200GB gp3
  月费用: ~$250 × 2台

集群部署 - AI服务器:
  实例类型: p3.2xlarge (含GPU)
  vCPU: 8核心
  内存: 61GB
  GPU: 1x Tesla V100
  存储: 500GB gp3
  月费用: ~$3,000 × 2台

集群部署 - 数据库服务器:
  实例类型: r6i.2xlarge
  vCPU: 8核心
  内存: 64GB
  存储: 1TB gp3
  月费用: ~$500
```

### 阿里云ECS推荐配置
```yaml
最小化部署:
  实例规格: ecs.c7.large
  vCPU: 2核心
  内存: 4GB
  存储: 100GB ESSD
  带宽: 5Mbps
  月费用: ~¥300

标准部署:
  实例规格: ecs.g7.2xlarge
  vCPU: 8核心
  内存: 32GB
  存储: 500GB ESSD
  带宽: 10Mbps
  月费用: ~¥1,800

集群部署 - 应用服务器:
  实例规格: ecs.c7.2xlarge
  vCPU: 8核心
  内存: 16GB
  存储: 200GB ESSD
  月费用: ~¥1,200 × 2台

集群部署 - AI服务器:
  实例规格: ecs.gn7i-c8g1.2xlarge
  vCPU: 8核心
  内存: 32GB
  GPU: 1x Tesla T4
  存储: 500GB ESSD
  月费用: ~¥4,000 × 2台
```

### 腾讯云CVM推荐配置
```yaml
最小化部署:
  实例类型: S5.LARGE8
  vCPU: 2核心
  内存: 8GB
  存储: 100GB SSD
  带宽: 5Mbps
  月费用: ~¥400

标准部署:
  实例类型: S5.2XLARGE16
  vCPU: 8核心
  内存: 16GB
  存储: 500GB SSD
  带宽: 10Mbps
  月费用: ~¥1,500

集群部署:
  应用服务器: S5.2XLARGE32 × 2台
  AI服务器: GN10Xp.2XLARGE40 × 2台 (含GPU)
  数据库服务器: M5.2XLARGE32 × 1台
  总月费用: ~¥15,000
```

## 📈 性能基准预测

### 响应时间预测
| 部署方案 | API响应 | 页面加载 | AI推理 | 文档处理 |
|----------|---------|----------|--------|----------|
| 最小化 | 2-5秒 | 3-8秒 | 10-30秒 | 30-120秒 |
| 标准 | 0.5-2秒 | 1-3秒 | 3-10秒 | 10-60秒 |
| 集群 | 0.2-1秒 | 0.5-2秒 | 1-5秒 | 5-30秒 |

### 并发能力预测
| 部署方案 | 并发用户 | QPS | 文档/小时 | 存储增长 |
|----------|----------|-----|----------|----------|
| 最小化 | 10-20 | 50 | 100 | 1-5GB/月 |
| 标准 | 50-100 | 200 | 500 | 5-20GB/月 |
| 集群 | 200-500 | 1000 | 2000 | 20-100GB/月 |

### 可用性预测
| 部署方案 | 可用性 | 故障恢复 | 数据安全 | 扩展性 |
|----------|--------|----------|----------|--------|
| 最小化 | 95% | 手动 | 本地备份 | 垂直扩展 |
| 标准 | 98% | 半自动 | 异地备份 | 有限扩展 |
| 集群 | 99.9% | 自动 | 多重备份 | 水平扩展 |

## 🎯 部署建议总结

### 根据团队规模选择方案
```yaml
小团队 (5-20人):
  推荐: 最小化部署
  服务器: 1台 (8GB RAM, 4核心)
  成本: $1,000-2,000/年
  部署时间: 2-4小时

中型团队 (20-100人):
  推荐: 标准单服务器部署
  服务器: 1台 (32GB RAM, 8核心)
  成本: $3,000-5,000/年
  部署时间: 4-8小时

大型团队 (100+人):
  推荐: 集群部署
  服务器: 3-6台
  成本: $15,000-30,000/年
  部署时间: 1-2天
```

### 分阶段部署策略
```yaml
第一阶段 (概念验证):
  - 使用最小化配置
  - 验证核心功能
  - 评估用户接受度
  - 时间: 1-2周

第二阶段 (试点部署):
  - 升级到标准配置
  - 导入部分业务数据
  - 小范围用户试用
  - 时间: 1-2个月

第三阶段 (全面部署):
  - 部署集群架构
  - 迁移所有数据
  - 全员使用
  - 时间: 3-6个月
```

### 风险评估和缓解
```yaml
技术风险:
  - 容器启动失败: 5% (配置完善)
  - 性能不达标: 10% (硬件充足)
  - 数据丢失: 2% (多重备份)
  - 安全漏洞: 5% (安全配置)

业务风险:
  - 用户接受度: 15% (培训和支持)
  - 数据迁移: 10% (分阶段迁移)
  - 运维能力: 20% (技能培训)

缓解措施:
  - 充分的测试和验证
  - 完善的备份和恢复
  - 详细的文档和培训
  - 专业的技术支持
```

---

**文档版本**: v1.0
**最后更新**: 2025-02-19
**适用环境**: Linux生产服务器
**支持系统**: Ubuntu 20.04+, CentOS 8+, RHEL 8+
